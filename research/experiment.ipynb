{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lenovo\\anaconda3\\envs\\mchatbot\\Lib\\site-packages\\pinecone\\index.py:4: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import Pinecone\n",
    "import pinecone\n",
    "from langchain.document_loaders import PyPDFLoader, DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.llms import CTransformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "PINECONE_API_KEY = \"pcsk_4VHfat_5R1UpNyPGQjpSYPca64yZS5Ta7JMHsy3RBgNLC8HGjjJFEEsrJRkHqZiDNbLkPr\"\n",
    "PINECONE_API_ENV = \"us-east-1-aws\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pdf(data):\n",
    "    loader = DirectoryLoader(data,\n",
    "                    glob=\"*.pdf\",\n",
    "                    loader_cls=PyPDFLoader)\n",
    "    \n",
    "    documents = loader.load()\n",
    "\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_data = load_pdf(\"F:\\Medical-ChatBot\\data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of my chunk: 5860\n"
     ]
    }
   ],
   "source": [
    "def text_split(extracted_data):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size = 500, chunk_overlap = 20)\n",
    "    text_chunks = text_splitter.split_documents(extracted_data)\n",
    "\n",
    "    return text_chunks\n",
    "text_chunks = text_split(extracted_data)\n",
    "print(\"length of my chunk:\", len(text_chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='<http://www.cdc.gov/niosh/w7_high.html>.\\nMaureen Haggerty\\nGALE ENCYCLOPEDIA OF MEDICINE 2 623\\nByssinosis\\nGEM -0433 to 0624 - B  10/22/03 6:09 PM  Page 623', metadata={'source': 'F:\\\\Medical-ChatBot\\\\data\\\\Medical_book.pdf', 'page': 636})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_chunks[5859]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_hugging_face_embeddings():\n",
    "    embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HuggingFaceEmbeddings(client=SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 256, 'do_lower_case': False}) with Transformer model: BertModel \n",
       "  (1): Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
       "  (2): Normalize()\n",
       "), model_name='sentence-transformers/all-MiniLM-L6-v2', cache_folder=None, model_kwargs={}, encode_kwargs={})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "embeddings = download_hugging_face_embeddings()\n",
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length 384\n"
     ]
    }
   ],
   "source": [
    "query_result = embeddings.embed_query(\"Hello world\")\n",
    "print(\"Length\", len(query_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.034477200359106064,\n",
       " 0.031023219227790833,\n",
       " 0.0067349993623793125,\n",
       " 0.02610897459089756,\n",
       " -0.03936201333999634,\n",
       " -0.16030248999595642,\n",
       " 0.06692397594451904,\n",
       " -0.006441470701247454,\n",
       " -0.04745051637291908,\n",
       " 0.014758859761059284,\n",
       " 0.07087533175945282,\n",
       " 0.05552757531404495,\n",
       " 0.019193289801478386,\n",
       " -0.026251329109072685,\n",
       " -0.010109508410096169,\n",
       " -0.026940548792481422,\n",
       " 0.022307483479380608,\n",
       " -0.022226618602871895,\n",
       " -0.14969265460968018,\n",
       " -0.01749304309487343,\n",
       " 0.007676269859075546,\n",
       " 0.05435226485133171,\n",
       " 0.003254482988268137,\n",
       " 0.03172600269317627,\n",
       " -0.0846213772892952,\n",
       " -0.02940598875284195,\n",
       " 0.051595672965049744,\n",
       " 0.04812409356236458,\n",
       " -0.003314794274047017,\n",
       " -0.05827922374010086,\n",
       " 0.041969284415245056,\n",
       " 0.022210709750652313,\n",
       " 0.1281888633966446,\n",
       " -0.022338956594467163,\n",
       " -0.011656241491436958,\n",
       " 0.06292833387851715,\n",
       " -0.032876305282115936,\n",
       " -0.09122610837221146,\n",
       " -0.03117538057267666,\n",
       " 0.05269957706332207,\n",
       " 0.047034792602062225,\n",
       " -0.08420304954051971,\n",
       " -0.0300561785697937,\n",
       " -0.020744718611240387,\n",
       " 0.009517784230411053,\n",
       " -0.003721792483702302,\n",
       " 0.007343328557908535,\n",
       " 0.03932436183094978,\n",
       " 0.09327410906553268,\n",
       " -0.0037885827478021383,\n",
       " -0.052742086350917816,\n",
       " -0.05805819109082222,\n",
       " -0.0068643949925899506,\n",
       " 0.005283229053020477,\n",
       " 0.08289298415184021,\n",
       " 0.019362755119800568,\n",
       " 0.0062844837084412575,\n",
       " -0.010330805554986,\n",
       " 0.009032356552779675,\n",
       " -0.037683770060539246,\n",
       " -0.04520607367157936,\n",
       " 0.02401638962328434,\n",
       " -0.0069442023523151875,\n",
       " 0.013491633348166943,\n",
       " 0.10005491971969604,\n",
       " -0.071683868765831,\n",
       " -0.02169504575431347,\n",
       " 0.03161846846342087,\n",
       " -0.05163463577628136,\n",
       " -0.08224768191576004,\n",
       " -0.06569331139326096,\n",
       " -0.00989536102861166,\n",
       " 0.0058163986541330814,\n",
       " 0.07355453819036484,\n",
       " -0.03405030816793442,\n",
       " 0.02488601580262184,\n",
       " 0.01448806282132864,\n",
       " 0.026457400992512703,\n",
       " 0.009656714275479317,\n",
       " 0.030217286199331284,\n",
       " 0.052803970873355865,\n",
       " -0.07535988092422485,\n",
       " 0.009897174313664436,\n",
       " 0.029836837202310562,\n",
       " 0.017555566504597664,\n",
       " 0.023091990500688553,\n",
       " 0.0019339261343702674,\n",
       " 0.0014001254457980394,\n",
       " -0.04717599228024483,\n",
       " -0.011194380931556225,\n",
       " -0.11420133709907532,\n",
       " -0.019812004640698433,\n",
       " 0.04026623070240021,\n",
       " 0.0021929889917373657,\n",
       " -0.07979222387075424,\n",
       " -0.02538231387734413,\n",
       " 0.09448292851448059,\n",
       " -0.02898111194372177,\n",
       " -0.14500252902507782,\n",
       " 0.23097743093967438,\n",
       " 0.027731100097298622,\n",
       " 0.032111480832099915,\n",
       " 0.031064996495842934,\n",
       " 0.04283281788229942,\n",
       " 0.06423777341842651,\n",
       " 0.03216314688324928,\n",
       " -0.00487674493342638,\n",
       " 0.055699415504932404,\n",
       " -0.03753236308693886,\n",
       " -0.0215055663138628,\n",
       " -0.028342649340629578,\n",
       " -0.028846941888332367,\n",
       " 0.03835311904549599,\n",
       " -0.01746867224574089,\n",
       " 0.05248536914587021,\n",
       " -0.07487605512142181,\n",
       " -0.03125976398587227,\n",
       " 0.021841533482074738,\n",
       " -0.03989564999938011,\n",
       " -0.008587109856307507,\n",
       " 0.026956573128700256,\n",
       " -0.04849550500512123,\n",
       " 0.011469874531030655,\n",
       " 0.029618263244628906,\n",
       " -0.020572170615196228,\n",
       " 0.013103901408612728,\n",
       " 0.028833406046032906,\n",
       " -3.194200554190157e-33,\n",
       " 0.0647820383310318,\n",
       " -0.018130239099264145,\n",
       " 0.051789943128824234,\n",
       " 0.12198273092508316,\n",
       " 0.028780145570635796,\n",
       " 0.0087220324203372,\n",
       " -0.07052115350961685,\n",
       " -0.01690724864602089,\n",
       " 0.040739696472883224,\n",
       " 0.042116180062294006,\n",
       " 0.02544722706079483,\n",
       " 0.03574619069695473,\n",
       " -0.04914474114775658,\n",
       " 0.002129100728780031,\n",
       " -0.015546616166830063,\n",
       " 0.05073058605194092,\n",
       " -0.048185259103775024,\n",
       " 0.03588063269853592,\n",
       " -0.004067067988216877,\n",
       " 0.10172475874423981,\n",
       " -0.05597001686692238,\n",
       " -0.010680987499654293,\n",
       " 0.011235800571739674,\n",
       " 0.09068652987480164,\n",
       " 0.004234495107084513,\n",
       " 0.035138655453920364,\n",
       " -0.009702835232019424,\n",
       " -0.09386523813009262,\n",
       " 0.09285551309585571,\n",
       " 0.00800494384020567,\n",
       " -0.007705416064709425,\n",
       " -0.052086714655160904,\n",
       " -0.012587959878146648,\n",
       " 0.0032668698113411665,\n",
       " 0.0060135237872600555,\n",
       " 0.007581581827253103,\n",
       " 0.010517198592424393,\n",
       " -0.08634552359580994,\n",
       " -0.06987876445055008,\n",
       " -0.0025338700506836176,\n",
       " -0.09097661077976227,\n",
       " 0.04688737168908119,\n",
       " 0.05207647755742073,\n",
       " 0.007193892262876034,\n",
       " 0.010903597809374332,\n",
       " -0.005229538772255182,\n",
       " 0.013937323354184628,\n",
       " 0.02196837216615677,\n",
       " 0.03420856222510338,\n",
       " 0.060224637389183044,\n",
       " 0.00011661044845823199,\n",
       " 0.014731992967426777,\n",
       " -0.07008922845125198,\n",
       " 0.02849903516471386,\n",
       " -0.027601642534136772,\n",
       " 0.010768351145088673,\n",
       " 0.03483092412352562,\n",
       " -0.022487878799438477,\n",
       " 0.00976911373436451,\n",
       " 0.07722778618335724,\n",
       " 0.021588344126939774,\n",
       " 0.11495622247457504,\n",
       " -0.06800113618373871,\n",
       " 0.023761043325066566,\n",
       " -0.015983911231160164,\n",
       " -0.01782696507871151,\n",
       " 0.06439494341611862,\n",
       " 0.03202573582530022,\n",
       " 0.05027022957801819,\n",
       " -0.005913649220019579,\n",
       " -0.03370799124240875,\n",
       " 0.017840316519141197,\n",
       " 0.01657339744269848,\n",
       " 0.06329654157161713,\n",
       " 0.03467720001935959,\n",
       " 0.04647345840930939,\n",
       " 0.09790614992380142,\n",
       " -0.006635494064539671,\n",
       " 0.02520708367228508,\n",
       " -0.0779883861541748,\n",
       " 0.01692640222609043,\n",
       " -0.0009457881096750498,\n",
       " 0.02247185818850994,\n",
       " -0.038253240287303925,\n",
       " 0.09570475667715073,\n",
       " -0.00535071175545454,\n",
       " 0.010469038039445877,\n",
       " -0.11524058878421783,\n",
       " -0.013262532651424408,\n",
       " -0.010709351859986782,\n",
       " -0.08311721682548523,\n",
       " 0.07327357679605484,\n",
       " 0.049392201006412506,\n",
       " -0.008994361385703087,\n",
       " -0.09584556519985199,\n",
       " 3.366149296434549e-33,\n",
       " 0.12493181973695755,\n",
       " 0.019349709153175354,\n",
       " -0.0582258477807045,\n",
       " -0.03598824888467789,\n",
       " -0.050746746361255646,\n",
       " -0.04566233605146408,\n",
       " -0.08260342478752136,\n",
       " 0.14819477498531342,\n",
       " -0.08842117339372635,\n",
       " 0.06027441471815109,\n",
       " 0.05103025957942009,\n",
       " 0.010303089395165443,\n",
       " 0.14121423661708832,\n",
       " 0.030813878402113914,\n",
       " 0.06103307381272316,\n",
       " -0.05285125970840454,\n",
       " 0.13664892315864563,\n",
       " 0.009189915843307972,\n",
       " -0.017325272783637047,\n",
       " -0.012848668731749058,\n",
       " -0.00799528043717146,\n",
       " -0.05098002031445503,\n",
       " -0.052350591868162155,\n",
       " 0.007593057118356228,\n",
       " -0.015166228637099266,\n",
       " 0.016960326582193375,\n",
       " 0.021270541474223137,\n",
       " 0.02055799402296543,\n",
       " -0.1200280711054802,\n",
       " 0.014461806043982506,\n",
       " 0.02675984986126423,\n",
       " 0.025330591946840286,\n",
       " -0.0427546426653862,\n",
       " 0.006768474821001291,\n",
       " -0.01445858832448721,\n",
       " 0.045261986553668976,\n",
       " -0.09147657454013824,\n",
       " -0.019439177587628365,\n",
       " -0.017833461984992027,\n",
       " -0.05491012707352638,\n",
       " -0.052641063928604126,\n",
       " -0.010459036566317081,\n",
       " -0.05201602354645729,\n",
       " 0.020892051979899406,\n",
       " -0.07997025549411774,\n",
       " -0.012111312709748745,\n",
       " -0.05773141607642174,\n",
       " 0.02317824214696884,\n",
       " -0.00803161971271038,\n",
       " -0.025989310815930367,\n",
       " -0.07995670288801193,\n",
       " -0.02072887495160103,\n",
       " 0.048817772418260574,\n",
       " -0.02038920484483242,\n",
       " -0.049176573753356934,\n",
       " 0.01415967382490635,\n",
       " -0.06362210959196091,\n",
       " -0.007807392161339521,\n",
       " 0.016431482508778572,\n",
       " -0.02568255178630352,\n",
       " 0.01338108442723751,\n",
       " 0.026248762384057045,\n",
       " 0.009978335350751877,\n",
       " 0.06322894990444183,\n",
       " 0.0026721502654254436,\n",
       " -0.006582724861800671,\n",
       " 0.016632026061415672,\n",
       " 0.03236645832657814,\n",
       " 0.03794251009821892,\n",
       " -0.036376021802425385,\n",
       " -0.006910946220159531,\n",
       " 0.00015967455692589283,\n",
       " -0.001633585779927671,\n",
       " -0.02727823331952095,\n",
       " -0.028038015589118004,\n",
       " 0.04968152567744255,\n",
       " -0.028867164626717567,\n",
       " -0.002418051240965724,\n",
       " 0.014774874784052372,\n",
       " 0.009764568880200386,\n",
       " 0.005797559395432472,\n",
       " 0.013486078940331936,\n",
       " 0.005567895248532295,\n",
       " 0.0372270792722702,\n",
       " 0.007232493255287409,\n",
       " 0.04015621170401573,\n",
       " 0.08150321245193481,\n",
       " 0.07199164479970932,\n",
       " -0.01305615995079279,\n",
       " -0.04288202524185181,\n",
       " -0.011011214926838875,\n",
       " 0.004897830542176962,\n",
       " -0.009229752235114574,\n",
       " 0.03519146889448166,\n",
       " -0.05103498697280884,\n",
       " -1.5714373802211412e-08,\n",
       " -0.08862444013357162,\n",
       " 0.0239093154668808,\n",
       " -0.01623874343931675,\n",
       " 0.03170047700405121,\n",
       " 0.027284175157546997,\n",
       " 0.05246879905462265,\n",
       " -0.04707096517086029,\n",
       " -0.058847445994615555,\n",
       " -0.0632082149386406,\n",
       " 0.04088853672146797,\n",
       " 0.049827940762043,\n",
       " 0.10655166208744049,\n",
       " -0.07450233399868011,\n",
       " -0.012495458126068115,\n",
       " 0.018370643258094788,\n",
       " 0.039474066346883774,\n",
       " -0.024797869846224785,\n",
       " 0.01451625395566225,\n",
       " -0.03706921264529228,\n",
       " 0.020015696063637733,\n",
       " -4.8594301915727556e-05,\n",
       " 0.00986657477915287,\n",
       " 0.024838784709572792,\n",
       " -0.05245809629559517,\n",
       " 0.029314136132597923,\n",
       " -0.08719196915626526,\n",
       " -0.014499745331704617,\n",
       " 0.026019057258963585,\n",
       " -0.018746383488178253,\n",
       " -0.07620513439178467,\n",
       " 0.035043250769376755,\n",
       " 0.10363949090242386,\n",
       " -0.02805054932832718,\n",
       " 0.012718234211206436,\n",
       " -0.07632549107074738,\n",
       " -0.018652433529496193,\n",
       " 0.02497669868171215,\n",
       " 0.08144541829824448,\n",
       " 0.06875890493392944,\n",
       " -0.0640566349029541,\n",
       " -0.08389392495155334,\n",
       " 0.061362382024526596,\n",
       " -0.033545587211847305,\n",
       " -0.10615341365337372,\n",
       " -0.04008050262928009,\n",
       " 0.03253019228577614,\n",
       " 0.07662486284971237,\n",
       " -0.07301613688468933,\n",
       " 0.0003375994274392724,\n",
       " -0.04087162762880325,\n",
       " -0.0757884681224823,\n",
       " 0.027527686208486557,\n",
       " 0.07462546974420547,\n",
       " 0.01771729253232479,\n",
       " 0.09121839702129364,\n",
       " 0.11022018641233444,\n",
       " 0.0005698270397260785,\n",
       " 0.05146332085132599,\n",
       " -0.014551276341080666,\n",
       " 0.03323199599981308,\n",
       " 0.023792244493961334,\n",
       " -0.022889798507094383,\n",
       " 0.03893755376338959,\n",
       " 0.030206795781850815]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No active indexes found in your Pinecone project, are you sure you're using the right API key and environment?",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[49], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m index_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmedicalbot\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m#Creating Embeddings for Each of The Text Chunks & storing\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m docsearch\u001b[38;5;241m=\u001b[39m\u001b[43mPinecone\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_texts\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpage_content\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtext_chunks\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_name\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\lenovo\\anaconda3\\envs\\mchatbot\\Lib\\site-packages\\langchain\\vectorstores\\pinecone.py:301\u001b[0m, in \u001b[0;36mPinecone.from_texts\u001b[1;34m(cls, texts, embedding, metadatas, ids, batch_size, text_key, index_name, namespace, **kwargs)\u001b[0m\n\u001b[0;32m    299\u001b[0m     index \u001b[38;5;241m=\u001b[39m pinecone\u001b[38;5;241m.\u001b[39mIndex(index_name)\n\u001b[0;32m    300\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(indexes) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 301\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    302\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo active indexes found in your Pinecone project, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    303\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mare you sure you\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mre using the right API key and environment?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    304\u001b[0m     )\n\u001b[0;32m    305\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    306\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    307\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIndex \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mindex_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m not found in your Pinecone project. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    308\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDid you mean one of the following indexes: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(indexes)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    309\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: No active indexes found in your Pinecone project, are you sure you're using the right API key and environment?"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "pinecone.init(api_key=PINECONE_API_KEY,\n",
    "              environment=PINECONE_API_ENV)\n",
    "\n",
    "index_name=\"medicalbot\"\n",
    "\n",
    "#Creating Embeddings for Each of The Text Chunks & storing\n",
    "docsearch=Pinecone.from_texts([t.page_content for t in text_chunks], embeddings, index_name=index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "# Creating embeddings for each text chunk and storing them in FAISS\n",
    "docsearch = FAISS.from_texts([t.page_content for t in text_chunks], embeddings)\n",
    "\n",
    "# Optional: Save the FAISS index for later use\n",
    "docsearch.save_local(\"faiss_index\")\n",
    "\n",
    "# Load the FAISS index (when needed)\n",
    "docsearch = FAISS.load_local(\"faiss_index\", embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: [Document(page_content='Purpose\\nAllergy is a reaction of the immune system. Nor-\\nmally, the immune system responds to foreign microor-\\nganisms and particles, like pollen or dust, by producing\\nspecific proteins called antibodies that are capable of\\nbinding to identifying molecules, or antigens, on the\\nforeign organisms. This reaction between antibody and\\nantigen sets off a series of reactions designed to protect\\nthe body from infection. Sometimes, this same series of', metadata={}), Document(page_content='reaction. Allergic rhinitis is characterized by an itchy,\\nrunny nose, often with a scratchy or irritated throat due\\nto post-nasal drip. Inflammation of the thin membrane\\ncovering the eye (allergic conjunctivitis) causes redness,\\nirritation, and increased tearing in the eyes. Asthma caus-\\nes wheezing, coughing, and shortness of breath. Symp-\\ntoms of food allergies depend on the tissues most sensi-\\ntive to the allergen and whether the allergen spread sys-', metadata={}), Document(page_content='KEY TERMS\\nAllergen —A substance that provokes an allergic\\nresponse.\\nAnaphylaxis—Increased sensitivity caused by pre-\\nvious exposure to an allergen that can result in\\nblood vessel dilation (swelling) and smooth mus-\\ncle contraction. Anaphylaxis can result in sharp\\nblood pressure drops and difficulty breathing.\\nAntibody —A specific protein produced by the\\nimmune system in response to a specific foreign\\nprotein or particle called an antigen.\\nAntigen —A foreign protein to which the body', metadata={})]\n"
     ]
    }
   ],
   "source": [
    "query = \"What are Allergies\"\n",
    "\n",
    "# Perform similarity search\n",
    "docs = docsearch.similarity_search(query, k=3)\n",
    "\n",
    "# Print the results\n",
    "print(\"Result:\", docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template=\"\"\"\n",
    "Use the following pieces of information to answer the user's question.\n",
    "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "\n",
    "Context: {context}\n",
    "Question: {question}\n",
    "\n",
    "Only return the helpful answer below and nothing else.\n",
    "Helpful answer:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT=PromptTemplate(template=prompt_template, input_variables=[\"context\", \"question\"])\n",
    "chain_type_kwargs={\"prompt\": PROMPT}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name_or_path = \"TheBloke/Llama-2-13B-Chat-GGML\"\n",
    "model_basename = \"llama-2-13b-chat.ggmlv3.q4_0.bin\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: huggingface_hub in c:\\users\\lenovo\\anaconda3\\envs\\mchatbot\\lib\\site-packages (0.26.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\lenovo\\anaconda3\\envs\\mchatbot\\lib\\site-packages (from huggingface_hub) (3.16.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\lenovo\\anaconda3\\envs\\mchatbot\\lib\\site-packages (from huggingface_hub) (2024.10.0)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\lenovo\\anaconda3\\envs\\mchatbot\\lib\\site-packages (from huggingface_hub) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\lenovo\\anaconda3\\envs\\mchatbot\\lib\\site-packages (from huggingface_hub) (6.0.2)\n",
      "Requirement already satisfied: requests in c:\\users\\lenovo\\anaconda3\\envs\\mchatbot\\lib\\site-packages (from huggingface_hub) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\lenovo\\anaconda3\\envs\\mchatbot\\lib\\site-packages (from huggingface_hub) (4.67.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\lenovo\\anaconda3\\envs\\mchatbot\\lib\\site-packages (from huggingface_hub) (4.12.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\lenovo\\anaconda3\\envs\\mchatbot\\lib\\site-packages (from tqdm>=4.42.1->huggingface_hub) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\lenovo\\anaconda3\\envs\\mchatbot\\lib\\site-packages (from requests->huggingface_hub) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\lenovo\\anaconda3\\envs\\mchatbot\\lib\\site-packages (from requests->huggingface_hub) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\lenovo\\anaconda3\\envs\\mchatbot\\lib\\site-packages (from requests->huggingface_hub) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\lenovo\\anaconda3\\envs\\mchatbot\\lib\\site-packages (from requests->huggingface_hub) (2024.8.30)\n",
      "Collecting llama-cpp-python==0.1.78\n",
      "  Downloading llama_cpp_python-0.1.78.tar.gz (1.7 MB)\n",
      "     ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "     ------------ --------------------------- 0.5/1.7 MB 2.8 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 1.6/1.7 MB 4.4 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 1.7/1.7 MB 4.4 MB/s eta 0:00:00\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\lenovo\\anaconda3\\envs\\mchatbot\\lib\\site-packages (from llama-cpp-python==0.1.78) (4.12.2)\n",
      "Requirement already satisfied: numpy>=1.20.0 in c:\\users\\lenovo\\anaconda3\\envs\\mchatbot\\lib\\site-packages (from llama-cpp-python==0.1.78) (1.23.4)\n",
      "Collecting diskcache>=5.6.1 (from llama-cpp-python==0.1.78)\n",
      "  Downloading diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)\n",
      "Downloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
      "Building wheels for collected packages: llama-cpp-python\n",
      "  Building wheel for llama-cpp-python (pyproject.toml): started\n",
      "  Building wheel for llama-cpp-python (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for llama-cpp-python: filename=llama_cpp_python-0.1.78-cp311-cp311-win_amd64.whl size=1156202 sha256=3e7e7fa62509feb4947fd0115b0dc2b78b90755128233b8355c83f1f48b645d8\n",
      "  Stored in directory: c:\\users\\lenovo\\appdata\\local\\pip\\cache\\wheels\\18\\69\\ad\\9b1cec6b18fe403616b8cfbf10021d1939cba077cee285c5c3\n",
      "Successfully built llama-cpp-python\n",
      "Installing collected packages: diskcache, llama-cpp-python\n",
      "Successfully installed diskcache-5.6.3 llama-cpp-python-0.1.78\n",
      "^C\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy==1.23.4 in c:\\users\\lenovo\\anaconda3\\envs\\mchatbot\\lib\\site-packages (1.23.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install huggingface_hub\n",
    "!pip install llama-cpp-python==0.1.78\n",
    "!pip install numpy==1.23.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error while downloading from https://cdn-lfs.hf.co/repos/cd/43/cd4356b11767f5136b31b27dbb8863d6dd69a4010e034ef75be9c2c12fcd10f7/f79142715bc9539a2edbb4b253548db8b34fac22736593eeaa28555874476e30?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27llama-2-13b-chat.ggmlv3.q4_0.bin%3B+filename%3D%22llama-2-13b-chat.ggmlv3.q4_0.bin%22%3B&response-content-type=application%2Foctet-stream&Expires=1732281658&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTczMjI4MTY1OH19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5oZi5jby9yZXBvcy9jZC80My9jZDQzNTZiMTE3NjdmNTEzNmIzMWIyN2RiYjg4NjNkNmRkNjlhNDAxMGUwMzRlZjc1YmU5YzJjMTJmY2QxMGY3L2Y3OTE0MjcxNWJjOTUzOWEyZWRiYjRiMjUzNTQ4ZGI4YjM0ZmFjMjI3MzY1OTNlZWFhMjg1NTU4NzQ0NzZlMzA%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qJnJlc3BvbnNlLWNvbnRlbnQtdHlwZT0qIn1dfQ__&Signature=RIJ2JTxLzNjQNDZ-bGqYmKqVSr9K5Uqwfnx0td%7EFwLAmwGqVD6hswIEIY7EuZ4AH1cOBEQUq8pSUOTf%7ESR%7ErtIPS0ScNHW6irfB22qjd4-j3PquU-UyuU4aXqoxvbw3sNl2zvEPTOi%7EHrsfp5TbdbHoHev1KKnrOo9jC2BOEn-bxZAOfyvKJdVKrLrKPOOEZQKXKL6SHJkrhD2ISikqIlTwVv-0R%7E7uJBBj3oljH2Nlp%7E1T6xXAOwzrQ6VtYE%7EaAHs5ydyzbJ2MHDzWF8hMTpxuZQuHzaGCWBNn007Cw3NyIoSzZ8NFR9FID-di5i81W1NRnxQH4OtN4lN-Y4S0Qkw__&Key-Pair-Id=K3RPWS32NSSJCE: HTTPSConnectionPool(host='cdn-lfs.hf.co', port=443): Read timed out.\n",
      "Trying to resume download...\n",
      "Error while downloading from https://cdn-lfs.hf.co/repos/cd/43/cd4356b11767f5136b31b27dbb8863d6dd69a4010e034ef75be9c2c12fcd10f7/f79142715bc9539a2edbb4b253548db8b34fac22736593eeaa28555874476e30?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27llama-2-13b-chat.ggmlv3.q4_0.bin%3B+filename%3D%22llama-2-13b-chat.ggmlv3.q4_0.bin%22%3B&response-content-type=application%2Foctet-stream&Expires=1732281658&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTczMjI4MTY1OH19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5oZi5jby9yZXBvcy9jZC80My9jZDQzNTZiMTE3NjdmNTEzNmIzMWIyN2RiYjg4NjNkNmRkNjlhNDAxMGUwMzRlZjc1YmU5YzJjMTJmY2QxMGY3L2Y3OTE0MjcxNWJjOTUzOWEyZWRiYjRiMjUzNTQ4ZGI4YjM0ZmFjMjI3MzY1OTNlZWFhMjg1NTU4NzQ0NzZlMzA%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qJnJlc3BvbnNlLWNvbnRlbnQtdHlwZT0qIn1dfQ__&Signature=RIJ2JTxLzNjQNDZ-bGqYmKqVSr9K5Uqwfnx0td%7EFwLAmwGqVD6hswIEIY7EuZ4AH1cOBEQUq8pSUOTf%7ESR%7ErtIPS0ScNHW6irfB22qjd4-j3PquU-UyuU4aXqoxvbw3sNl2zvEPTOi%7EHrsfp5TbdbHoHev1KKnrOo9jC2BOEn-bxZAOfyvKJdVKrLrKPOOEZQKXKL6SHJkrhD2ISikqIlTwVv-0R%7E7uJBBj3oljH2Nlp%7E1T6xXAOwzrQ6VtYE%7EaAHs5ydyzbJ2MHDzWF8hMTpxuZQuHzaGCWBNn007Cw3NyIoSzZ8NFR9FID-di5i81W1NRnxQH4OtN4lN-Y4S0Qkw__&Key-Pair-Id=K3RPWS32NSSJCE: HTTPSConnectionPool(host='cdn-lfs.hf.co', port=443): Read timed out.\n",
      "Trying to resume download...\n",
      "c:\\Users\\lenovo\\anaconda3\\envs\\mchatbot\\Lib\\site-packages\\huggingface_hub\\file_download.py:139: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\lenovo\\.cache\\huggingface\\hub\\models--TheBloke--Llama-2-13B-Chat-GGML. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import hf_hub_download\n",
    "from llama_cpp import Llama\n",
    "model_path = hf_hub_download(repo_id=model_name_or_path, filename=model_basename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\lenovo\\\\.cache\\\\huggingface\\\\hub\\\\models--TheBloke--Llama-2-13B-Chat-GGML\\\\snapshots\\\\3140827b4dfcb6b562cd87ee3d7f07109b014dd0\\\\llama-2-13b-chat.ggmlv3.q4_0.bin'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm=CTransformers(model=model_path,\n",
    "                  model_type=\"llama\",\n",
    "                  config={'max_new_tokens':512,\n",
    "                          'temperature':0.8})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa=RetrievalQA.from_chain_type(\n",
    "    llm=llm, \n",
    "    chain_type=\"stuff\", \n",
    "    retriever=docsearch.as_retriever(search_kwargs={'k': 2}),\n",
    "    return_source_documents=True, \n",
    "    chain_type_kwargs=chain_type_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    user_input=input(f\"Input Prompt:\")\n",
    "    result=qa({\"query\": user_input})\n",
    "    print(\"Response : \", result[\"result\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mchatbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
